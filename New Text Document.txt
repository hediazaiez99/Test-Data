import gradio as gr
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.llms import HuggingFacePipeline
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM

# === Charger le PDF une seule fois au d√©marrage ===
pdf_path = "CELEX_52013XC0802(04)_EN_TXT (1) GUIDELINE.pdf"
loader = PyPDFLoader(pdf_path)
documents = loader.load()

splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.split_documents(documents)

embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectordb = Chroma.from_documents(chunks, embedding=embedding_model, persist_directory="./chroma_local_guideline")
retriever = vectordb.as_retriever()

# === LLM (Flan-T5) ===
model_id = "google/flan-t5-base"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForSeq2SeqLM.from_pretrained(model_id)

llm_pipeline = pipeline(
    "text2text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=256
)

# === Temp store pour question qui attend un pays ===
temp_context = {"last_question_needing_country": None}

# === Pays ou proc√©dures accept√©s ===
eu_keywords = [
    "france", "germany", "italy", "centralised", "national", "mrp", "spain",
    "ireland", "belgium", "portugal", "austria", "netherlands", "denmark",
    "sweden", "finland", "greece", "czech", "hungary", "romania", "slovakia"
]

# === Fonction principale ===
def smart_chat(user_input, history):
    try:
        keywords = ["batch size", "fold", "increase", "scale up"]
        user_input_lower = user_input.lower()

        # 1. Si c‚Äôest une question contextuelle sans pays
        if any(kw in user_input_lower for kw in keywords) and not any(word in user_input_lower for word in eu_keywords):
            temp_context["last_question_needing_country"] = user_input
            return " In which country or procedure context is this question relevant?"

        # 2. Si on re√ßoit une r√©ponse pays apr√®s une question contextuelle
        if temp_context["last_question_needing_country"]:
            country_input = user_input_lower.strip()
            if not any(valid in country_input for valid in eu_keywords):
                temp_context["last_question_needing_country"] = None
                return "‚ö†Ô∏è This guideline only applies to EU member states or recognized EU procedures. Tunisia is not covered."
            question_with_country = f"In the context of {user_input}, {temp_context['last_question_needing_country']}"
            user_input = question_with_country
            temp_context["last_question_needing_country"] = None

        # 3. Chercher dans la base vectorielle
        relevant_docs = retriever.get_relevant_documents(user_input)

        if relevant_docs and any(doc.page_content.strip() for doc in relevant_docs):
            context = "\n".join([doc.page_content for doc in relevant_docs[:2]])
            prompt = f"""
You are a regulatory expert assistant.

Based on the following context extracted from an official EU guideline document, 
explain clearly and concisely the answer to the question below. If the question asks for a comparison (e.g. differences), provide a structured comparison.

Context:
{context}

Question: {user_input}
Answer:
""".strip()
            response = llm_pipeline(prompt)[0]['generated_text']
        else:
            # 4. Si pas de doc trouv√©, question g√©n√©rale
            prompt = f"Answer the following question clearly:\n{user_input}"
            response = llm_pipeline(prompt)[0]['generated_text']

        return response.strip()

    except Exception as e:
        print(f"Exception: {e}")
        return f"‚ö†Ô∏è Error: {str(e)}"

# === Interface Gradio ===
gr.ChatInterface(
    smart_chat,
    title="üìÑ Smart PDF Chatbot (EU Guidelines + General Q&A)",
    description="Ask about the EU guideline PDF or general knowledge. If the question involves batch size but lacks a country, the bot will ask for clarification."
).launch()
